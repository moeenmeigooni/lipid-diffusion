"""
Main script for training and sampling POPC lipid diffusion model.
"""

import numpy as np
import torch
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
from natsort import natsorted
import random
import glob

from lipid_diffusion.data.preprocessor import LipidCoordinatePreprocessor
from lipid_diffusion.data.dataset import LipidDataset
from lipid_diffusion.models.transformer import AtomwiseTransformer
from lipid_diffusion.models.gnn import LipidGraphNetwork
from lipid_diffusion.models.diffusion import DiffusionModel
from lipid_diffusion.models.flow_matching import FlowMatchingTrainer
from lipid_diffusion.training.trainer import train_diffusion_model, generate_samples

def write_xyz(coordinates, filename):
    atom_names = ['N', 'C12', 'H12A', 'H12B', 'C13', 'H13A', 'H13B', 'H13C', 'C14',
 'H14A', 'H14B', 'H14C', 'C15', 'H15A', 'H15B', 'H15C', 'C11', 'H11A', 'H11B', 'P', 'O13', 'O14', 'O12',
 'O11', 'C1', 'HA', 'HB', 'C2', 'HS', 'O21', 'C21', 'O22', 'C22', 'H2R', 'H2S', 'C3', 'HX', 'HY',
 'O31', 'C31', 'O32', 'C32', 'H2X', 'H2Y', 'C23', 'H3R', 'H3S', 'C24', 'H4R', 'H4S', 'C25', 'H5R', 'H5S',
 'C26', 'H6R', 'H6S', 'C27', 'H7R', 'H7S', 'C28', 'H8R', 'H8S', 'C29', 'H91', 'C210', 'H101', 'C211', 'H11R',
 'H11S', 'C212', 'H12R', 'H12S', 'C213', 'H13R', 'H13S', 'C214', 'H14R', 'H14S', 'C215', 'H15R', 'H15S',
 'C216', 'H16R', 'H16S', 'C217', 'H17R', 'H17S', 'C218', 'H18R', 'H18S', 'H18T', 'C33', 'H3X', 'H3Y',
 'C34', 'H4X', 'H4Y', 'C35', 'H5X', 'H5Y', 'C36', 'H6X', 'H6Y', 'C37', 'H7X', 'H7Y', 'C38', 'H8X',
 'H8Y', 'C39', 'H9X', 'H9Y', 'C310', 'H10X', 'H10Y', 'C311', 'H11X', 'H11Y', 'C312', 'H12X', 'H12Y',
 'C313', 'H13X', 'H13Y', 'C314', 'H14X', 'H14Y', 'C315', 'H15X', 'H15Y', 'C316', 'H16X', 'H16Y', 'H16Z']
    atom_names = [name[0] for name in atom_names if name[0] != 'H']
    n_atoms = len(coordinates)
    with open(filename, 'w') as f:
        f.write(f'{n_atoms}\n\n')
        for i, (coord, atom_name) in enumerate(zip(coordinates, atom_names)):
            f.write(f'{atom_name}\t{coord[0]:8.5f}\t{coord[1]:8.5f}\t{coord[2]:8.5f}\n')

def write_pdb(coordinates, filename, chain_id='A', res_name='LIP', res_num=1):
    """
    Write coordinates to a PDB file.

    Args:
        coordinates: (n_atoms, 3) array of coordinates
        filename: Output PDB filename
        chain_id: Chain identifier
        res_name: Residue name (e.g., 'POPC')
        res_num: Residue number
    """
    # POPC atom names - temporary workaround
    atom_names = ['N', 'C12', 'H12A', 'H12B', 'C13', 'H13A', 'H13B', 'H13C', 'C14',
 'H14A', 'H14B', 'H14C', 'C15', 'H15A', 'H15B', 'H15C', 'C11', 'H11A', 'H11B', 'P', 'O13', 'O14', 'O12',
 'O11', 'C1', 'HA', 'HB', 'C2', 'HS', 'O21', 'C21', 'O22', 'C22', 'H2R', 'H2S', 'C3', 'HX', 'HY',
 'O31', 'C31', 'O32', 'C32', 'H2X', 'H2Y', 'C23', 'H3R', 'H3S', 'C24', 'H4R', 'H4S', 'C25', 'H5R', 'H5S',
 'C26', 'H6R', 'H6S', 'C27', 'H7R', 'H7S', 'C28', 'H8R', 'H8S', 'C29', 'H91', 'C210', 'H101', 'C211', 'H11R',
 'H11S', 'C212', 'H12R', 'H12S', 'C213', 'H13R', 'H13S', 'C214', 'H14R', 'H14S', 'C215', 'H15R', 'H15S',
 'C216', 'H16R', 'H16S', 'C217', 'H17R', 'H17S', 'C218', 'H18R', 'H18S', 'H18T', 'C33', 'H3X', 'H3Y', 
 'C34', 'H4X', 'H4Y', 'C35', 'H5X', 'H5Y', 'C36', 'H6X', 'H6Y', 'C37', 'H7X', 'H7Y', 'C38', 'H8X',
 'H8Y', 'C39', 'H9X', 'H9Y', 'C310', 'H10X', 'H10Y', 'C311', 'H11X', 'H11Y', 'C312', 'H12X', 'H12Y',
 'C313', 'H13X', 'H13Y', 'C314', 'H14X', 'H14Y', 'C315', 'H15X', 'H15Y', 'C316', 'H16X', 'H16Y', 'H16Z']
    atom_names = [name for name in atom_names if name[0] != 'H']
    with open(filename, 'w') as f:
        f.write("REMARK   Generated by POPC Lipid Diffusion Model\n")
        f.write(f"REMARK   {len(coordinates)} atoms\n")

        for i, (coord, atom_name) in enumerate(zip(coordinates, atom_names)):
            # PDB format: ATOM serial name resName chainID resSeq x y z occupancy tempFactor element
            line = (
                f"ATOM  {i+1:5d}  {atom_name:4s}{res_name:3s} {chain_id}{res_num:4d}    "
                f"{coord[0]:8.3f}{coord[1]:8.3f}{coord[2]:8.3f}  1.00  0.00           "
                f"{atom_name[0]:2s}\n"
            )
            f.write(line)

        f.write("END\n")

def main():
    """Example pipeline for training and sampling."""
    
    # 1. Load and preprocess data
    print("Loading coordinate data...")
    preprocessor = LipidCoordinatePreprocessor()

    file_paths = natsorted(glob.glob('../pdbs/conf*.pdb'))
    random.shuffle(file_paths)
    coords_normalized, atom_types = preprocessor.process_dataset(file_paths, format='pdb')
    n_atoms = coords_normalized.shape[1]

    print(f"Loaded {len(coords_normalized)} conformations with {coords_normalized.shape[1]} atoms each")
    unique_types, counts = np.unique(atom_types, return_counts=True)
    print(f"Atom types: {dict(zip(unique_types, counts))}")

    # 2. Split dataset into train and test sets (80/20 split)
    dataset = LipidDataset(coords_normalized, atom_types)
    train_size = int(0.8 * len(dataset))
    test_size = len(dataset) - train_size

    train_dataset, test_dataset = random_split(
        dataset,
        [train_size, test_size],
        generator=torch.Generator().manual_seed(42)  # For reproducibility
    )

    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)

    print(f"Train set: {train_size} conformations")
    print(f"Test set: {test_size} conformations")

    # 3. Initialize model
    device = 'mps' if torch.backends.mps.is_available() else 'cpu'
    print(f"Using device: {device}")

    #model = AtomwiseTransformer(
    #    n_atoms=n_atoms,
    #    hidden_dim=256,
    #    n_heads=4,
    #    n_layers=5,
    #    num_atom_types=dataset.num_atom_types,
    #    use_atom_types=True
    #)

    model = LipidGraphNetwork(
        n_atoms=n_atoms,
        hidden_dim=512,
        num_layers=4,
        num_heads=4,
        num_rbf=50,  # Increased from 16 for better bond resolution
        cutoff=5.0,   # Reduced from 15.0 to focus on bonded interactions
        dropout=0.05,
        num_atom_types=dataset.num_atom_types,
        use_atom_types=True
    )

    #diffusion = DiffusionModel(
    #    model=model,
    #    n_timesteps=1000,
    #    beta_start=1e-4,
    #    beta_end=2e-2
    #)

    diffusion = FlowMatchingTrainer(  # Same variable name for compatibility
        model=model,
        noise_schedule='vp',  # 'ot' or 'vp'
        stochastic=False      # True for stochastic sampling
    )
    
    # Move diffusion schedule to device
    diffusion.to(device)

        # 4. Train with early stopping
    print("\nTraining model...")
    train_losses, test_losses, best_epoch = train_diffusion_model(
        train_dataloader=train_dataloader,
        test_dataloader=test_dataloader,
        model=model,
        diffusion=diffusion,
        n_epochs=500,
        lr=1e-4,
        device=device,
        patience=30,
        min_delta=1e-4,
        save_path='outputs/best_model.pt'
    )
    
    print(f"\nTraining completed. Best model at epoch {best_epoch+1}")
    
    # 5. Load best model for generation
    print("\nLoading best model for generation...")
    checkpoint = torch.load('outputs/best_model.pt', map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # 6. Generate new samples
    print("Generating new conformations...")
    new_conformations = generate_samples(
        diffusion=diffusion,
        n_samples=10,
        n_atoms=n_atoms,
        device=device,
        atom_types=dataset.atom_type_indices.to(device)
    )
    #new_conformations = diffusion.sample(
    #    shape=(10, 52, 3),
    #    method='rk4',
    #    num_steps=25  # Much faster than diffusion!
    #).cpu()
    
    # Denormalize
    new_conformations_real = preprocessor.denormalize(new_conformations)
    
    print(f"Generated {len(new_conformations_real)} new conformations")
    print(f"Shape: {new_conformations_real.shape}")
    
    # 7. Save results
    # Save each conformation as a separate PDB file
    for i, conf in enumerate(new_conformations_real):
        xyz_filename = f'outputs/generated_conf_{i+1:03d}.xyz'
        write_xyz(conf, xyz_filename)#, chain_id='A', res_name='POPC')
    
    print(f"Saved {len(new_conformations_real)} PDB files")
    
    # Also save as numpy for convenience
    np.save('outputs/generated_conformations.npy', new_conformations_real)
    
    # 8. Plot training and test losses
    plt.figure(figsize=(12, 5))
    
    # Plot losses
    plt.subplot(1, 2, 1)
    epochs = range(1, len(train_losses) + 1)
    plt.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    plt.plot(epochs, test_losses, 'r-', label='Test Loss', linewidth=2)
    plt.axvline(x=best_epoch+1, color='g', linestyle='--', label=f'Best Epoch ({best_epoch+1})')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Test Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot log scale for better visualization if losses vary greatly
    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)
    plt.plot(epochs, test_losses, 'r-', label='Test Loss', linewidth=2)
    plt.axvline(x=best_epoch+1, color='g', linestyle='--', label=f'Best Epoch ({best_epoch+1})')
    plt.xlabel('Epoch')
    plt.ylabel('Loss (log scale)')
    plt.title('Training and Test Loss (Log Scale)')
    plt.yscale('log')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('outputs/training_loss.png', dpi=300)
    plt.close()
    
    print("\nDone! Results saved to 'outputs/' directory")
    print(f"  - {len(new_conformations_real)} PDB files: generated_conf_001.pdb, ...")
    print(f"  - Best model checkpoint: best_model.pt (epoch {best_epoch+1})")
    print(f"  - Training loss plot: training_loss.png")
    print(f"  - Final train loss: {train_losses[-1]:.6f}")
    print(f"  - Final test loss: {test_losses[-1]:.6f}")


if __name__ == '__main__':
    main()
